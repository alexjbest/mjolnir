\title{ST202 Stochastic Processes - Lecture Notes}
\author{Based on lectures by Dr Krzysztof \L atuszy\'nski}
\date{\today}

\documentclass{article}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{hyperref}
\usepackage{ulem,MnSymbol,enumerate}


\newtheorem{thm}{Theorem}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{prop}[thm]{Proposition}
\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}
\newtheorem{defns}[thm]{Definitions}
\newtheorem{ex}[thm]{Example}
\newtheorem{exer}{Exercise}
\newtheorem{rem}[thm]{Remark}
\newtheorem{nota}{Notation}
%\newtheorem*{alg}{Algorithm}

\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\QQ}{\mathbb{Q}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\PP}{\mathbb{P}}
%\newcommand{\x}{\mathbf{x}}
%\newcommand{\X}{\mathcal{X}}
%\newcommand{\I}{\mathcal{I}}
%\newcommand{\J}{\mathcal{J}}
%\newcommand{\B}{\mathcal{B}}

\newcommand{\bb}[1]{\mathbb{#1}}

\setcounter{tocdepth}{3}

\begin{document}
\maketitle
\tableofcontents

\section{Introduction}
Notes for ST202.
\clearpage

\section{02/10/12 Lecture 1}

\paragraph*{Into/Recap}

Stochastic Process is a random phenomenon evolving in time.

\begin{defn} A stochastic process $X$ is a family $\{ X_t | t \in T \}$ of R.Vs indexed by a time-set $T$. The hard part about this is that it is dependent (behaving in a dynamic way).\\

$T$: time set ($T$ is typically the natural numbers but not always).\\

State space of $X$: all the possible states that $X$ can be in.\\
\end{defn}

\begin{ex}
Gambler's Ruin - We toss a sequence of fair coins. You pay me \pounds1 for each head and I pay you \pounds1 for each tail. I start with \pounds10 and you start with \pounds100, don't spend it all at once. We play until one of us runs out of money.

\paragraph*{Define that game}

Define $X_n = x$ if you have \pounds$x$ after toss $n$ (then $X_0 = 100$). The sequence $\{ X_1, X_2, \ldots \}$ is a stochastic process. The state-space is $\{0, 1, 2, \ldots, 110 \}$.
\end{ex}

\section{05/10/12 Lecture 2}

\begin{ex}
Hanging words - This is a stochastic process with a large $S$ ``roughly $26^3$''

\[
\begin{array}{ccccccc}
\mbox{\underline{Start Word}} & & & & & \mbox{\underline{Finish Word}} \\
\downarrow & & & & & \downarrow \\
\mbox{rat} & \rightarrow & \mbox{rot} & \rightarrow \mbox{dot} & \rightarrow & \mbox{dog}
\end{array}
\]

You have to change from start to finish by changing one letter at a time, so that all intermediate steps are words.
\end{ex}

\paragraph*{Use a Computer}

\begin{itemize}
\item
Dictionary
\item
random number Generator
\end{itemize}

Then we apply the following algorithm.

\begin{enumerate}
\item
Choose a position in the word at random
\item
Choose one of the letters that previously hasn't been in this position (at random)
\item
Check if the word is in the dictionary
\item
If not decline
\item
If in the dictionary accept
\item
Repeat this process until you have the word
\end{enumerate}

\begin{ex}Simple random Walk - Here is a random walk with a variable probability $p$ and $1-p$.\\

$X_0 = 0$\\
$X_n = X_{n-1} \pm 1 \rightarrow$ Probability $p$, $1-p$ respectively.
\indent $S = \mathbb{Z}$, $T = \mathbb{N}$
\end{ex}

\begin{defn} The path space, is a set of all paths that you process can take e.g. your state space raised to the power of the amount of iterations you process can take.
\end{defn}

\begin{defn} An \underline{Event} is a sub set of the path-space.\\
\end{defn}
 
e.g. all paths that do not exceed 10 for the first 100 steps.\\

e.g. Event: all paths that satisfies $X_2 = 0$

\begin{defn} $X = \{ X_n : n = 0,1,2, \ldots \}$ is said to be a discrete state-space Markov chain if

\begin{enumerate}
\item
$S$ - is a discrete state space
\item
Markov property holds
\end{enumerate}
\indent\indent The conditional probabilities of the future given the past depend only on the present.
\[
\mathbb{P} ( X_{n+1} = x_{n+1} \mid X_n = x_n, X_{n-1} = x_{n-1}, \ldots, X_0 = x_0 ) =
\]
\[
\indent\indent \mathbb{P}(X_{n+1} = x_{n+1} \mid X_n = x_n) \hspace*{0.05 in} \forall \mbox{ n } \forall x_i \mbox{ i } \in \{1,2, \ldots, N \}
\]
\end{defn}

\paragraph*{Intuition} $\mathbb{P}$ ( future $\mid$ present and past) = $\mathbb{P}$ ( future $\mid$ present )

\begin{defn} The discrete state space Markov Chains is said to have stationary transition probabilities if
\[
p_{i,j} = \mathbb{P} ( X_{m+1} = i \mid X_m = j) 
\] 

do not get `large' with time.
\end{defn}

\begin{ex} A really simple weather model\\

$X_n = w$ if wet on day $n$\\
$\hspace*{0.15 in}$ $X_n$ = $d$ if dry on day $n$\\

$\mathbb{P}$ (wet tomorrow $\mid$ wet today ) = 0.8\\
$\hspace*{0.15 in}$ $\mathbb{P}$ (dry tomorrow $\mid$ dry today ) = 0.7\\

or\\

$\mathbb{P} (X_{n+1} = w \mid X_n = w) = 0.8\Leftrightarrow\mathbb{P} (X_{n+1} = d \mid X_n = w ) = 0.2$\\
$\hspace*{0.15 in} \mathbb{P} (X_{n+1} = d \mid X_n = d ) = 0.7 \Leftrightarrow \mathbb{P} (X_{n+1} = w \mid X_n = d ) = 0.3$\\
\end{ex}

\begin{ex} A simple weather model\\

$\mathbb{P} (X_{n+1} = w \mid X_n = w ) = 0.6 + \frac{\mid J(n) - 180 \mid}{350}$ 
$\hspace*{0.15 in} \mathbb{P} (X_{n+1} = d \mid X_n = d ) = 0.5 - \frac{\mid J(n) - 180 \mid}{350}$

with $J(n)$ is equal to the number of days in years. 
\end{ex}

\section{05/10/12 Lecture 3}

\begin{defn} Mc = discrete state-space Markov chain with stationary transition probabilities.
\end{defn}

\begin{defn} Stationary transition probabilities and transition probability matrices.
\end{defn}

\begin{enumerate}
\item
the (one-step)probability (kernel) from $j$ to $k$ is denoted by
\[
P_{jk} = p(j,k) = \mathbb{P}(X_{m+1} = K \mid X_m = j) \mbox{k, j }\in S^{\infty} = \{1,2,\ldots, N\}
\]
\item
the (one-step) transition probability matrix is denoted by
\[
\uuline{P} = [P(j,k)]_{j,k \in S}
\]
\item
the $n$-step transition probabilities and transition probability matrices are respectively defined as
\[
P_{jk}^{(n)} = P^{(n)} (j, k) = \mathbb{P}(X_{m+n} = k \mid X_m = j) 
\]
and
\[
\uuline{P}^{(n)} = [P^{(n)} (j,k) ]_{j,k \in S}
\]
\end{enumerate}

\begin{ex}
The really simple weather model - let $d=2$ and $w = 1$, so $S = \{d,w\} = \{2,1\}$

\[
\uuline{P}^{(n)} = \left [ \begin{array}{cc} 0.8 & 0.2 \\ 0.3 & 0.7 \end{array} \right ] \hspace*{0.5 in} n > 0
\]

with

\[
\uuline{P}^{(0)} = \left [ \begin{array}{cc} 1 & 0 \\ 1 & 1 \end{array} \right ]
\]
\end{ex}

\begin{rem} $\uuline{P}^{(0)} = T_{\mid S \mid \times \mid S \mid}$ because
\[
P^{(0)}(j,k) = \begin{cases} 1 \mbox{ j = k}\\ 0 \mbox{ j} \neq \mbox{ k} \end{cases}
\]
\end{rem}

\begin{rem} $\uuline{P}$ is a stochastic matrix, i.e.
\begin{itemize}
\item
row sums = 1
\item
entries $\geq$ 0
\end{itemize}
also $\uuline{P}^n$ is a stochastic matrix.
\end{rem}

\begin{thm} Distribution of a MC is fully specified by (1) and (2)
\begin{itemize}
\item
the distribution of its initial state $x_0$
\item
its (one step) transition probability
\end{itemize}
\end{thm}

i.e. given (1) and (2) we can calculate the probability of any event occurring X.

\begin{proof} For any path $\{k_0, k_1, \ldots, k_{n-1}, k_n\}$ over the initial time segment $\{0, 2, \ldots, n \}$

\[
\mathbb{P}(x \mbox{ follows } \{k_0, k_1, \ldots, k_n \}) = \mathbb{P}(X \mbox{ follows } \{k_0, k_1, \ldots, k_n \} \mid X \mbox{ follows } \{k_0, k_1, \ldots, k_{n-1} \}) 
\]
\[
\times \mathbb{P}(X \mbox{ follows } \{k_0, k_1, \ldots, k_{n-1} \}) =
\]
\[
= \mathbb{P}(X_n = k_n \mid X \mbox{ follows } \{(k_0, k_1, \ldots, k_{n-1} \}) \times \mathbb{P}(X \mbox{ follows } \{ k_0, k_1, \ldots, k_{n-1} \} ) =
\]
\[ = \mathbb{P}(X_n = k_n \mid X_{n-1} = k_{n-1} ) \times \mathbb{P}(X \mbox{ follows } \{k_0, k_1, \ldots, k_{n-1} \}) =
\]
\[
= \mathbb{P}(k_{n-1}, k_{n} ) \mathbb{P}(k_{n-2}, k_{n-1}) \mathbb{P}(X \mbox{ follows } \{ k_0, k_1, \ldots, k_{n-2} \}) = \ldots
\]
\[
\ldots = \mathbb{P}(k_{n-1}, k_{n} ) \mathbb{P}(k_{n-2}, k_{n-1}) \ldots \mathbb{P}(k_0, k_1) \frac{\mathbb{P}(X \mbox{ follows } \{k_0\})}{\mathbb{P} (x_0 = k_0)}
\]
\end{proof}

\begin{ex} Weather model

\[
\uuline{P} = \left [ \begin{array}{cc} 0.8 & 0.2 \\ 0.3 & 0.7 \end{array} \right ] \hspace*{0.5 in} n > 0
\]

We start with dry weather 
\[
\mathbb{P}(ddwd) = \mathbb{P}(\{X_1, X_2, X_3,X_4\} ) = \{d,d,w,d\} = 1 \times 0.7 \times 0.3 \times 0.2
\] 
\end{ex}

\begin{thm} Chapman Kolmogorov equations -
Suppose X is a MC, then
\[
\uuline{P}^{(n + m)} = \uuline{P}^{(n)} \uuline{P}^{(m)} \mbox{ ie } \uuline{P}_{ij}^{(n+m)} = \sum_{k \in S} P_{ik}^{(n)} P_{kj}^{(m)}
\]
\end{thm}

\begin{proof} First we start with

\[
P_{ij}^{n+m} = \mathbb{P}(X_{n+m} = j \mid X_0 = i )= \mathbb{P}((\bigcup_{k \in S} \{ X_{n+m} = j, X_n = k \} \mid X_0 = i) =
\]
\[ = \sum_{k \in S} \mathbb{P}(X_{n+m} = j, X_n = k \mid X_0 = i) = \sum_{k \in S} \mathbb{P}(X_{n+m} = j \mid X_n = k, X_0 = i ) \times \mathbb{P} (X_n = k \mid X_0 = i) = 
\]
\[ = \sum_{k \in S} \mathbb{P} (X_{n+m} = j \mid X_n = k) \times \mathbb{P}(X_n = k \mid X_0 = i) = \sum_{k \in S} P^{(m)}(k,j) P^{(n)}(i,k)
\]
\end{proof}

\begin{thm} Distribution of $X_n$
\[
a_i^{(n)} = \mathbb{P}(X_n) = i
\]
Then $a^{(n)} = a^{(0)} \uuline{P}^{(n)}$, with $a^{(n)}$ being a vector.
\end{thm}

\begin{proof}
\[
a_i^n = \sum_{k \in S} \mathbb{P} (X_n = i \mid X_0 = k ) \times \mathbb{P}[X_0 = k] = \sum_{k \in S} P^{(n)} (k,i) a_k^{(0)}
\] 
\end{proof}

\section{09/10/12 Lecture 4}

\paragraph*{Recall:} transition matrix
\[
\uuline{P^{n+m}} = \uuline{P^{n}} \cdot \uuline{P^{m}} 
\]
if $a^{(n)}$ is the distribution of $X_n$, then $a^{(n)} = a^{(0)} \times \uuline{P^{n}} = a^{(n-1)}\uuline{P}$.

\begin{ex} Let $S = \{1, 2, 3\}$ be our state-space and
\[
\uuline{P^{1}} =  \left [ \begin{array}{ccc}
1 & 0 & 0\\ 0.5 & 0 & 0.5\\ 0 & 0.5 & 0.5 \end{array} \right ]
\]
If we start with $X_0 \sim a^{(0)} = [ 0,0,1 ]$ then, $X_1 \sim a^{(1)} = a^{(0)} \uuline{P^{1}} = [0,0.5,0.5]$, then $X_2 \sim a^{(2)} = a^{(0)} \uuline{P^{2}} = a^{1}\uuline{P^1} = [ 0.25, 0.25, 0.5 ]$ and so on $\ldots$
\end{ex}

\paragraph*{Note} Easy to do $2\times2$ or $3\times3$ matrices but for bigger matrices it is easier to use some software.

\paragraph*{State diagram:} directed graph, vertices are the states, directed edges are the possible one step transitions

\begin{ex} $\{Y_n, n \geq 1 \}$ idd taking values in $\{-1, 0, 1\}$ with probabilities $\{q, r, p\}$. Obviously $q + r + p = 1$, the sequence of partial sums $\{X_n = X_{n-1} + Y_n L n \geq 1\}$ forms a Markov chain with tridiagonal transition matrix
\[
\uuline{P^1} = \left [ \begin{array}{ccccccc}
\ddots & \vdots & \vdots & \vdots & \vdots & \vdots & \udots\\
\hdots & q & r & p & 0 & 0 & \hdots\\
\hdots & 0 & q & r & p & 0 & \hdots\\
\hdots & 0 & 0 & q & r & p & \hdots\\
\udots & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots\\
\end{array} \right ]
\]
$a_i^{(0)} = \mathbb{P}(X_0 = i)$ - infinite vector. Distribution of $Y$ is the jump distribution.
\end{ex}

\paragraph*{Variations}
\begin{enumerate}
\item
Absorbing or reflecting barriers.
\item
Random walk behaviours on $\mathbb{Z}^2, \mathbb{Z}^3$ etc.
\item
Can take arbitrary jump distribution for $Y$.
\end{enumerate}

\begin{ex}
Algorithm at the production line
\begin{enumerate}
\item
Test every item until $i+1$ consecutive non-deflective items are found.
\item
Test each item at random  with probability $1/r$ until a defective item is found; switch to $(1)$.
\end{enumerate}
Our task is to model this with a Markov chain. So we set our statespace as $S = \{E_0, E_1, \ldots E_i, E_{\ast} \}$, with state $E_j$ begin checking the $j^{th}$ item and $E_{\ast}$ be the state where we check an item with probability $1/r$. $X_m$ is the state of the machine at the $m^{th}$ time.
\[
\mathbb{P}[ \mbox{go from } E_{\ast} \mbox{ to } E_0 ] = 1/r \times p = p/r
\] 
\[
\uuline{P} = \left [ \begin{array}{ccccc} p & 1-p & 0 & \hdots & 0\\ p & 0 & 1 - p & \hdots & 0\\ \vdots & \vdots & \vdots & \vdots & \vdots\\ p & 0 & 0 & \hdots & 1 - p\\ p/r & 0 & 0 & \hdots & 1 - p/r \end{array} \right ]
\]
\end{ex}

\begin{ex} Discrete time m/G/1 queue - service times are iid and independent distributed as $\mathbb{P}(S_n = r)$, number of arrivals = $b_r$.  At each point of time, there is a new arrival with probability $p$; arrivals are idd. Inter arrival times $\{A_n : n > 0\}$ are idd, geometric. $\PP(A_n = r) = (1-p)^{-1}p$. The number of people in the queue at time $m$ is not in general a Markov Chain. However define\\

$Q_n$ - the length of the queue at the time of $n^{th}$ departure. This is a stochastic process we are interested in.
\end{ex}

\section{12/10/12 Lecture 5}

\paragraph*{Note} $Q_{n+1} - Q_n$ - the number of people arrived during the service time of $(n+1)^st$ customer minus 1. This is independent of $Q_0, Q_1, \ldots Q_{n-1}$ once $Q_n$ is known. Hence $Q_n$ is a Markov chain.

\[
Q_{n+1} = \begin{cases} Q_n - 1 + N_{n+1} & \mbox{ if } Q_n > 0,\\ N_{n+1} & \mbox{ if } Q_n = 0 \end{cases}
\]

$N_{n+1}$ - the number of arrivals to the queue in the time-interval during which customer $n+1$ is being served.\\

$\PP(N_n = j) = k_j = \sum_{r=j}^{\inf}$ $\PP(j$ arrivals in service time $\mid$ service time $= r)b_r$ = $\sum_{r=k}^{\inf} \binom{r}{j} p^j(1-p)^{r-j}b_r$.\\

Hence the transition matrix of $Q_n$ is

\[
\uuline{P} = \left [ \begin{array}{ccccc}
k_0 & k_1 & k_2 & k_3 & \hdots\\
k_0 & k_1 & k_2 & k_3 & \hdots\\
0 & k_0 & k_1 & k_2 & \hdots\\
0 & 0 & k_0 & k_1 & \hdots\\
\vdots & \vdots & \vdots & \vdots & \ddots\\
\end{array} \right ]
\]

$Q_n^{\ast}$ - the length of the queue at time of $n^{th}$ arrival.\\

$Q_n^{\ast}$ is not a Markov chain. (Has something to do with the forgetting property of the geometric distributions).\\

What is the distribution of the waiting time for a typical customer?

\paragraph*{Classification of States}

If it is possible to travel from $a \rightarrow b$ and $b \rightarrow a$, then $a$ and $b$ share many properties.

\begin{defn} $i,j \in S$
\begin{enumerate}
\item
$i$ \uline{leads to} $j$ ($i \rightarrow j$) if $\exists_{n>0}$ such that $p_{ij}^{(n)} > 0$.
\item
$i$, $j$ \uline{intercommunicate} ($i \leftrightarrow j$) if $i \rightarrow j$ and $j \rightarrow i$.
\item
$i, j$ are in the same \uline{communicating class} ($i \sim j$) of states if either $i \leftrightarrow j$ or $i = j$.
\end{enumerate}
\end{defn}

\paragraph*{For example 23:}

\begin{itemize}
\item
2 leads to 1 $(p_{2,1}^{(1)} = 1/3 > 0)$
\item
2 leads to 2 $(p_{2,2}^{(3)} \geq p_{2,4}^(1)p_{4,3}^{(1)}p_{3,2}^{(1)} > 0)$
\item
2 leads to 3 $(p_{2,3}^{(1)} = 1/3 > 0)$
\item
2 leads to 4 $(p_{2,4}^{(1)} = 1/3 > 0)$
\end{itemize}

Similarly, 3 leads to 1,2,3,4 and 4 leads to 1,2,3,4. However 1 leads to 1 and nothing else. States $\{2,3,4\}$ intercommunicate and also 1 intercommunicates with itself.

\begin{thm} The relation $\sim$ is an equivalence relation. \end{thm}

\begin{proof}
\begin{enumerate}
\item
Reflexive: $i \sim i$ since $i=i$.
\item
Symmetric: $i \sim j$ then $j \sim i$ immediate from definition.
\item
Transitive: suppose $i \sim j$ and $j \sim k$ if either $i=j$ or $i=k$ or $j=k$ then we are done. Otherwise if $i \rightarrow j$ and $k \rightarrow k$ then $p_{i,j}^{(n)} > 0$ and $p_{j,k}^{(m)}$ for some $m,n > 0$. Thus from Chapman-Kolmogorov  $p_{i,k}^{(m+n)} \geq p_{i,j}^{(n)}p_{j,k}^{(m)}>0$ and $i \rightarrow k$. We get $k \rightarrow i$ by a symmetric arguments therefore $i \sim k$.
\end{enumerate}
\end{proof}

\section{12/10/12 Lecture 6}
\begin{ex}
%TODO add picture
$$\uuline{P} = \begin{bmatrix}
1 & 0 & 0 & 0 \\
\frac13 & 0 & \frac13 & \frac13 \\
0 & 1 & 0 & 0 \\
0 & 0 & \frac12 & \frac12 \\
\end{bmatrix}$$
\end{ex}

\paragraph{Recall example} Random walk with two barriers:
%TODO picture
Conclusion: pattern of zeros in $\uuline{P}$ implies division into communicating classes.

\begin{defn}
\begin{enumerate}[(a)]
\item $i\in S$ is \emph{essential} if $\forall j\in S\ (i\rightarrow j \text{ implies } j\rightarrow i)$.
\item The stochastic matrix $\uuline P$ is \emph{irreducible} if all states intercommunicate ($S$ is one single communicating class).
\end{enumerate}
\end{defn}

In example 23 only $\{1\}$ is essential and $\uuline P$ is not irreducible. \\
In recalled example, $O$ and $K$ are essential $\uuline P$ is not irreducible.

\begin{ex}
M/G/1 queue is irreducible.
$$\uuline P = \begin{bmatrix}
k_0 & k_1 & k_2 & \hdots \\
k_0 & k_1 & k_2 & \hdots \\
0 & k_0 & k_1 & \hdots \\
\vdots & \vdots & \vdots & \ddots \\
\end{bmatrix}$$
Note that if $k_0,k_1,k_2$ are positive then the MC is irreducible.
\end{ex}

\begin{lem}
Suppose $i\rightarrow k$ and $i$ is essential.
Then $k$ is essential and $i\sim k$
%TODO picture
\end{lem}
\begin{proof}
$i\rightarrow k$, $i$ is essential, then by definition 26(a) $k\rightarrow i$ and $i\sim k$. \\
Moreover suppose $k\rightarrow j$, then 
$$\left.\begin{aligned}i &\rightarrow k \\ k &\rightarrow j\end{aligned}\right\} \implies i\rightarrow j \text{ therefore }\left.\begin{aligned}j &\rightarrow i \\ i &\rightarrow k\end{aligned}\right\} \implies j\rightarrow k$$
so $k$ is essential.
\end{proof}

\subsection*{Periodicity}
\begin{defn}
The \emph{period} of a state is the greatest common divisor (gcd) of times at which the chain might return to the state. Thus:
\begin{enumerate}[(a)]
\item $i$ has period $\gcd\{n \colon P_{ii}^{(n)} > 0\}$ if $i \rightarrow i$.
\item If $i\rightarrow i$ doesn't hold then the period of $i$ is not defined.
\item If $i$ has period 1 then it is said to be aperiodic.
\end{enumerate}
\end{defn}

\begin{ex}
\textbf{(a)}
%TODO picture
What is the period of 1 in this example? 3,4,\ldots (number of steps you can return to 1 in).
$\gcd\{3,4,\ldots\} = 1$ so this example is aperiodic.\\
\textbf{(b)}
%TODO picture
Period of 1: \\
2,4,6,8,\ldots \\
$\gcd\{2,4,6,8,\ldots\} = 2$.
So the period of 1 is 2.
\end{ex}

\begin{thm} Periodicity is a class property \end{thm}
\begin{proof}
$a\mid b$ -- positive integer $a$ divides positive integer $b$. \\
Suppose $a\leftrightarrow j$ and $i$ has period $d$.
Since $i\leftrightarrow j$ $\exists n,m$ s.t. $P_{ij}^{(n)} > 0$ and $P_{ji}^{(m)}>0$.
Since $\operatorname{period}(i) = d$, if $P_{ii}^{(k)}>0 \implies d\mid k$.
If $P_{jj}^{(r)}> 0$ then $P_{ii}^{(n+r+m)} \ge P_{ij}^{(n)}P_{jj}^{(r)}P_{ji}^{(m)}>0$ thus $d\mid n+r+m$.
Since also $d\mid n+m$, thus $d\mid r$.
Therefore $\operatorname{period}(j)$ is a multiple of $\operatorname{period}(i) = d$.
Swap the role of $i$ and $j$ to obtain that $\operatorname{period}(i)$ is a multiple of $\operatorname{period}(j)$.
Therefore they are the same.
\end{proof}

\begin{lem}
Suppose that $i\rightarrow i$ and that $\operatorname{period}(i) = d$.
Then $\exists N>0$ s.t. $\forall k\ge N$, $P_{ii}^{(kd)} >0$.
\end{lem}

\begin{ex}
%TODO picture
period$(i) = 2$
\end{ex}

\section{16/10/12 Lecture 7}

\subsection*{Recurrence and Transience}

\begin{ex} You play a gambler's ruin game. Your capital is \pounds 10. You opponent has unlimited credit. What happens if you win with probability $p > 0.5$? $S = \{0, 1, 2, \ldots\}$.\\

Two communicating classes
\begin{itemize}
\item
\{0\} - essential and aperiodic
\item
\{1,2,$\ldots$\} - not essential and of period 2
\end{itemize}
\end{ex}

\paragraph*{Questions}
\begin{itemize}
\item
$\PP$(X hits 0 before time $n = r_n = $?
\item
$\lim_{n \rightarrow \inf} r_n = 1$? (It may depend on $p$)
\end{itemize}

\begin{defn}
First Passage time distribution - Let $f_{i,j}^{(n)} = \PP(X_n = j, X_m \neq j$ for $m = 1, 2, \ldots n-1$)\\

$T_{i,j}$ - the first passage time from $i$ to $j$, is a random variable distributed as $\PP[T_{i,j} = n \mid X_0 = i ] = 1 - f_{i,j}^{(n)}$. Also $\PP[T_{i,j} = \inf \mid X_0 = i] = 1 - f_{i,j}^{(\ast)}$ with $f_{i,j}^{(\ast)} = \sum_{n=1}^{\inf} f_{ij}^{(n)}$. 
\end{defn}

\begin{defn}
The state j is
\begin{enumerate}
\item
recurrent (or persistent) if $f_{j,j}^{(\ast)} = 1$.
\item
transient if $f_{j,j}^{(\ast)} < 1$.
\end{enumerate}
\end{defn}

\subsection*{First-step decomposition}

\[
f_{i,j}^{(1)} = p_{i,j}
\]
\[
n \geq 1, f_{i,j}^{n+1} = \sum_{l:l\neq j} p_{i,l}f_{l,j}^{(n)} = \sum_{l: l \rightarrow j, l \neq j} p_{i,l}f_{l,j}
\]
if we sum over $n$:
\[
f_{i,j}^{(\ast)} = p_{i,j} + \sum_{l : l \rightarrow j, l \neq j} p_{i,j}f_{l,j}^{(\ast)}
\]

\begin{ex}
Players A and B choosing sequences of coin tosses $\{H, T\}$.
Player A chooses THH.
Player B choose TTH.
And they wait until one of the sequences occurs first for e.g. THTHTHH, then A wins.\\

We can model the game by a Markov Chain. We let state 1 be no pattern of note, state 2 'T', 3 'TT', 4 'TTH', 5 'TH' and 6 'THH'.

\[
\uuline{P} = \left [ \begin{array}{cccccc}
0.5 & 0.5 & 0 & 0 & 0 & 0\\
0 & 0 & 0.5 & 0 & 0.5 & 0\\
0 & 0 & 0.5 & 0.5 & 0 & 0\\
0 & 0 & 0 & 1 & 0 & 0\\
0 & 0.5 & 0 & 0 & 0 & 0.5\\
0 & 0 & 0 & 0 & 0 & 1
\end{array} \right ]
\]

we want to calculate $f_{1,4}^{(\ast)}$ and $f_{1,6}^{(\ast)}$. To find out, which one has a better chance of winning?\\

\[
f_{1,4}^{(\ast)} = 0.5 f_{1,4}^{(\ast)} + 0.5 f_{2,4}^{(\ast)} \hspace*{0.5 in} \Rightarrow \hspace*{0.5 in} f_{1,4}^{(\ast)} = f_{2,4}^{(\ast)}
\]
Now
\[
f_{2,4}^{(\ast)} = 0.5 f_{3,4}^{(\ast)} + 0.5 f_{5,4}^{(\ast)}
\]
So lets look at the first element $f_{3,4}^{(\ast)}$
\[
f_{3,4}^{(\ast)} = 0.5 f_{3,4}^{(\ast)} + 0.5 f_{4,4}^{(\ast)} = 0.5 + f_{3,4}^{(\ast)} 0.5 \hspace*{0.5 in} \Rightarrow \hspace*{0.5 in} f_{3,4}^{(\ast)} = 1
\]
then the second element $f_{5,4}^{(\ast)}$
\[
f_{5,4}^{(\ast)} = 0.5 f_{2,4}^{(\ast)} + 0.5 f_{6,4}^{(\ast)} = 0.5 f_{2,4}^{(\ast)}
\]
putting it all together
\[
f_{1,4}^{(\ast)} = 0.5 (1) + 0.5 (0.5 f_{2,4}^{(\ast)}) = 0.5 + 0.25 f_{1,4}^{(\ast)} \hspace*{0.5 in} \Rightarrow \hspace*{0.5 in} f_{1,4}^{(\ast)} = 2/3
\]
What is $f_{1,6}^{\ast}$ You can repeat as above or realise that the game must end so we have $f_{1,6}^{\ast} = 1 - f_{1,4}^{\ast} = 1/3$.
\end{ex}

\subsection*{First Passage decomposition}
\[
p_{i,j}^{(n)} = \sum_{m=1}^n f_{i,j}^{(m)}p_{j,j}^{n-m} \hspace*{0.5 in} n > 0
\]
Prove this by dividing $\PP(X_n = j \mid X_0 = i)$ into a partition according to the first time $X$ visits $j$. Alternatively, setting $m = n - u$, rewrite
\[
p_{i,j}^{(n)} = \sum_{u = 0}^{n-1} f_{i,j}^{(n-u)}p_{j,j}^{(u)} \hspace*{0.5 in} n> 0
\]
\subsection*{Converting into generating functions}
\[
P_{i,j}(s) = \sum_{n=0}^{\inf} p_{i,j}^{(n)}s^n; \hspace*{0.5 in} F_{i,j}(s) = \sum_{n=0}^{\inf}f_{i,j}s^n
\]
\begin{lem} For $\mid s \mid < 1$
\[
P_{i,j}(s) = p_{i,j}^{(0)} + F_{i,j}(s)P_{j,j}(s)
\]
\end{lem}

\section{--/--/-- Lecture 8}

\section{--/--/-- Lecture 9}

\section{--/--/-- Lecture 10}

\section{--/--/-- Lecture 11}

\section{--/--/-- Lecture 12}

\section{--/--/-- Lecture 13}

\section{--/--/-- Lecture 14}

\section{--/--/-- Lecture 15}

\section{--/--/-- Lecture 16}

\section{--/--/-- Lecture 17}

\section{--/--/-- Lecture 18}

\section{--/--/-- Lecture 19}

\section{--/--/-- Lecture 20}

\section{--/--/-- Lecture 21}

\section{--/--/-- Lecture 22}

\section{--/--/-- Lecture 23}

\section{--/--/-- Lecture 24}

\section{--/--/-- Lecture 25}

\section{--/--/-- Lecture 26}

\section{--/--/-- Lecture 27}

\section{--/--/-- Lecture 28}

\section{--/--/-- Lecture 29}

\section{--/--/-- Lecture 30}

\end{document}
